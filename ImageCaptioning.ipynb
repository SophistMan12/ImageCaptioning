{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import thư viện\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng features: 8091\n",
      "5 key đầu tiên trong features: ['378453580_21d688748e', '379006645_b9a2886b51', '380034515_4fbdfa6b26', '380041023_0dfd712ef1', '380515798_c2abbf46b0']\n",
      "Shape của feature đầu tiên: (1, 2048)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('features.pkl', 'rb') as f:\n",
    "    all_features = pickle.load(f)\n",
    "\n",
    "# Loại bỏ đuôi .jpg để key là ID\n",
    "features = {k.split('.')[0]: v for k, v in all_features.items()}\n",
    "\n",
    "print(f\"Số lượng features: {len(features)}\")\n",
    "print(\"5 key đầu tiên trong features:\", list(features.keys())[:5])\n",
    "print(\"Shape của feature đầu tiên:\", list(features.values())[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng descriptions: 8091\n",
      "5 key đầu tiên trong descriptions: ['1000268201_693b08cb0e', '1001773457_577c3a7d70', '1002674143_1b742ab4b8', '1003163366_44323f5815', '1007129816_e794419615']\n",
      "5 caption đầu tiên của ảnh đầu tiên: ['startseq child in a pink dress is climbing up a set of stairs in an entry way . endseq', 'startseq girl going into a wooden building . endseq', 'startseq little girl climbing into a wooden playhouse . endseq', 'startseq little girl climbing the stairs to her playhouse . endseq', 'startseq little girl in a pink dress going into a wooden cabin . endseq']\n"
     ]
    }
   ],
   "source": [
    "def load_descriptions(doc):\n",
    "    descriptions = {}\n",
    "    lines = doc.strip().split('\\n')\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line or line.lower().startswith(\"image\"):\n",
    "            continue\n",
    "        try:\n",
    "            image_id, image_desc = line.split(maxsplit=1)\n",
    "            image_id = image_id.split('.')[0]\n",
    "            caption = f\"startseq {image_desc} endseq\"\n",
    "            descriptions.setdefault(image_id, []).append(caption)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return descriptions\n",
    "\n",
    "with open('captions.txt', 'r') as f:\n",
    "    doc = f.read()\n",
    "    descriptions = load_descriptions(doc)\n",
    "\n",
    "print(f\"Số lượng descriptions: {len(descriptions)}\")\n",
    "print(\"5 key đầu tiên trong descriptions:\", list(descriptions.keys())[:5])\n",
    "print(\"5 caption đầu tiên của ảnh đầu tiên:\", list(descriptions.values())[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng ảnh có cả features và descriptions: 8091\n",
      "5 key đầu tiên sau khi lọc: ['1000268201_693b08cb0e', '1001773457_577c3a7d70', '1002674143_1b742ab4b8', '1003163366_44323f5815', '1007129816_e794419615']\n"
     ]
    }
   ],
   "source": [
    "features = {k: features[k] for k in descriptions.keys() if k in features}\n",
    "print(f\"Số lượng ảnh có cả features và descriptions: {len(features)}\")\n",
    "print(\"5 key đầu tiên sau khi lọc:\", list(features.keys())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8415\n",
      "5 từ đầu tiên trong tokenizer: [('startseq', 1), ('endseq', 2), ('a', 3), ('in', 4), ('the', 5)]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "all_captions = [caption for captions_list in descriptions.values() for caption in captions_list]\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_captions)\n",
    "\n",
    "print(f\"Vocabulary size: {len(tokenizer.word_index) + 1}\")\n",
    "print(\"5 từ đầu tiên trong tokenizer:\", list(tokenizer.word_index.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 shape: (437606, 1, 2048)\n",
      "X2 shape: (437606, 39)\n",
      "y shape: (437606,)\n",
      "5 feature đầu tiên (X1): [[[0.1227762  0.33293068 0.75272447 ... 0.21941456 0.30208504 0.40279704]]\n",
      "\n",
      " [[0.1227762  0.33293068 0.75272447 ... 0.21941456 0.30208504 0.40279704]]\n",
      "\n",
      " [[0.1227762  0.33293068 0.75272447 ... 0.21941456 0.30208504 0.40279704]]\n",
      "\n",
      " [[0.1227762  0.33293068 0.75272447 ... 0.21941456 0.30208504 0.40279704]]\n",
      "\n",
      " [[0.1227762  0.33293068 0.75272447 ... 0.21941456 0.30208504 0.40279704]]]\n",
      "5 sequence đầu tiên (X2): [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  1 42]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  1 42  4]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  1 42  4  3]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  1 42  4  3 88]]\n",
      "5 nhãn đầu tiên (y): [ 42   4   3  88 170]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "max_length = max(len(caption.split()) for caption in all_captions)\n",
    "\n",
    "def create_sequences(tokenizer, max_len, descriptions, features):\n",
    "    X1, X2, y = [], [], []\n",
    "    for img_id, caption_list in descriptions.items():\n",
    "        if img_id not in features:\n",
    "            continue\n",
    "        feature = features[img_id]\n",
    "        for desc in caption_list:\n",
    "            seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "            if len(seq) < 2:\n",
    "                continue\n",
    "            for i in range(1, len(seq)):\n",
    "                in_seq, out_seq = seq[:i], seq[i]\n",
    "                in_seq = pad_sequences([in_seq], maxlen=max_len)[0]\n",
    "                X1.append(feature)\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "    return np.array(X1), np.array(X2), np.array(y)\n",
    "\n",
    "X1, X2, y = create_sequences(tokenizer, max_length, descriptions, features)\n",
    "print(f\"X1 shape: {X1.shape}\")\n",
    "print(f\"X2 shape: {X2.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "print(\"5 feature đầu tiên (X1):\", X1[:5])\n",
    "print(\"5 sequence đầu tiên (X2):\", X2[:5])\n",
    "print(\"5 nhãn đầu tiên (y):\", y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,154,240</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8415</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,162,655</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m524,544\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m2,154,240\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m525,312\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m65,792\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8415\u001b[0m)      │  \u001b[38;5;34m2,162,655\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,432,543</span> (20.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,432,543\u001b[0m (20.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,432,543</span> (20.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,432,543\u001b[0m (20.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
    "\n",
    "# Tham số đầu vào\n",
    "vocab_size = 8415   # tổng số từ trong tokenizer + 1\n",
    "max_length = 39     # chiều dài chuỗi đầu vào (caption) đã padding\n",
    "embedding_dim = 256 # chiều không gian embedding\n",
    "feature_dim = 2048  # đầu ra của ResNet50, Xception, etc.\n",
    "\n",
    "# Đầu vào 1: đặc trưng ảnh (shape: 1 x 2048)\n",
    "inputs1 = Input(shape=(1, feature_dim))\n",
    "x1 = Dense(256, activation='relu')(inputs1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = tf.keras.layers.Reshape((256,))(x1)  # bỏ chiều (1,) để ghép được\n",
    "\n",
    "# Đầu vào 2: dãy từ (shape: max_length,)\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "x2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)(inputs2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "x2 = LSTM(256)(x2)\n",
    "\n",
    "# Kết hợp 2 nhánh\n",
    "decoder = add([x1, x2])\n",
    "decoder = Dense(256, activation='relu')(decoder)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder)\n",
    "\n",
    "# Tạo model\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(descriptions, features, tokenizer, max_length, batch_size):\n",
    "    while True:\n",
    "        X1, X2, y = list(), list(), list()\n",
    "        n = 0\n",
    "        for key, desc_list in descriptions.items():\n",
    "            for desc in desc_list:\n",
    "                # encode ảnh\n",
    "                seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "                for i in range(1, len(seq)):\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                    out_seq = tf.keras.utils.to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\n",
    "                    X1.append(features[key])\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "                    n += 1\n",
    "                    if n == batch_size:\n",
    "                        yield [np.array(X1), np.array(X2)], np.array(y)\n",
    "                        X1, X2, y = list(), list(), list()\n",
    "                        n = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Định nghĩa output signature đúng cách\n",
    "output_signature = (\n",
    "    (\n",
    "        tf.TensorSpec(shape=(None, 1, 2048), dtype=tf.float32),  # image feature\n",
    "        tf.TensorSpec(shape=(None, max_length), dtype=tf.int32)  # input sequence\n",
    "    ),\n",
    "    tf.TensorSpec(shape=(None, vocab_size), dtype=tf.float32)  # output word (one-hot)\n",
    ")\n",
    "\n",
    "# Tạo dataset\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(descriptions, features, tokenizer, max_length, batch_size),\n",
    "    output_signature=output_signature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:132\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.multi_step_on_iterator\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmulti_step_on_iterator\u001b[39m(iterator):\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mOptional\u001b[38;5;241m.\u001b[39mfrom_value(\n\u001b[1;32m--> 132\u001b[0m             \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m         )\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     empty_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mOptional\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "dataset = dataset.cache()\n",
    "\n",
    "batch_size = 64  # Đặt batch size tại đây\n",
    "steps = len(y) // batch_size\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    dataset,\n",
    "    steps_per_epoch=steps,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Tạo thư mục Result\n",
    "import os\n",
    "\n",
    "# Tạo đường dẫn đầy đủ\n",
    "result_dir = r\"D:\\CaptionImage\\Result\"\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "print(f\"Created directory: {result_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Lưu model và tokenizer\n",
    "print(\"Saving model...\")\n",
    "model_path = os.path.join(result_dir, 'image_captioning_model')\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "print(\"Saving tokenizer...\")\n",
    "tokenizer_path = os.path.join(result_dir, 'tokenizer.pkl')\n",
    "with open(tokenizer_path, 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(f\"Tokenizer saved to: {tokenizer_path}\")\n",
    "\n",
    "# Lưu thêm max_length để sử dụng sau này\n",
    "max_length_path = os.path.join(result_dir, 'max_length.txt')\n",
    "with open(max_length_path, 'w') as f:\n",
    "    f.write(str(max_length))\n",
    "print(f\"Max length saved to: {max_length_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import thêm thư viện cần thiết\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import sacrebleu\n",
    "\n",
    "# Cell 2: Hàm đánh giá BLEU score\n",
    "def evaluate_caption(generated, reference):\n",
    "    # Chuẩn cho nltk\n",
    "    reference_tokens = [reference.strip().lower().split()]\n",
    "    candidate_tokens = generated.strip().lower().split()\n",
    "\n",
    "    bleu_nltk = sentence_bleu(reference_tokens, candidate_tokens,\n",
    "                             smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    # Chuẩn cho sacrebleu\n",
    "    bleu_sacre = sacrebleu.sentence_bleu(generated, [reference.strip().lower()])\n",
    "\n",
    "    return bleu_nltk, bleu_sacre.score\n",
    "\n",
    "# Cell 3: Load model và các thành phần cần thiết\n",
    "def load_model_and_components():\n",
    "    result_dir = r\"D:\\CaptionImage\\Result\"\n",
    "    \n",
    "    # Load model\n",
    "    model_path = os.path.join(result_dir, 'image_captioning_model')\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer_path = os.path.join(result_dir, 'tokenizer.pkl')\n",
    "    print(f\"Loading tokenizer from: {tokenizer_path}\")\n",
    "    with open(tokenizer_path, 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "    \n",
    "    # Load max_length\n",
    "    max_length_path = os.path.join(result_dir, 'max_length.txt')\n",
    "    print(f\"Loading max_length from: {max_length_path}\")\n",
    "    with open(max_length_path, 'r') as f:\n",
    "        max_length = int(f.read())\n",
    "    \n",
    "    return model, tokenizer, max_length\n",
    "\n",
    "# Cell 4: Hàm trích xuất đặc trưng ảnh\n",
    "def extract_features(image_path):\n",
    "    # Load InceptionV3 model\n",
    "    model = InceptionV3(weights='imagenet')\n",
    "    model = tf.keras.Model(model.input, model.layers[-2].output)\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = load_img(image_path, target_size=(299, 299))\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    \n",
    "    # Extract features\n",
    "    features = model.predict(image, verbose=0)\n",
    "    return features\n",
    "\n",
    "# Cell 5: Hàm tạo caption\n",
    "def generate_caption(image_path, model, tokenizer, max_length):\n",
    "    # Extract features\n",
    "    features = extract_features(image_path)\n",
    "    \n",
    "    # Initialize caption\n",
    "    caption = 'startseq'\n",
    "    \n",
    "    # Generate caption\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([caption])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = model.predict([features, sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = tokenizer.index_word.get(yhat, '')\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "        caption += ' ' + word\n",
    "    \n",
    "    return caption.replace('startseq ', '')\n",
    "\n",
    "# Cell 6: Chạy pipeline đánh giá\n",
    "def run_evaluation_pipeline():\n",
    "    # Load model và components\n",
    "    model, tokenizer, max_length = load_model_and_components()\n",
    "    \n",
    "    # Đường dẫn ảnh và caption mẫu\n",
    "    img_path = 'Test_image.png'\n",
    "    reference_caption = \"some children are riding on a mini orange train\"\n",
    "    \n",
    "    # Tạo caption\n",
    "    caption = generate_caption(img_path, model, tokenizer, max_length)\n",
    "    \n",
    "    # In kết quả\n",
    "    print(\"📷 Ảnh test:\", img_path)\n",
    "    print(\"✍️  Caption mẫu (đề bài):\", reference_caption)\n",
    "    print(\"🤖 Caption từ model:\", caption)\n",
    "    \n",
    "    # Đánh giá BLEU score\n",
    "    bleu_nltk, bleu_sacre = evaluate_caption(caption, reference_caption)\n",
    "    print(\"\\n🔵 BLEU (nltk):\", round(bleu_nltk, 4))\n",
    "    print(\"🟢 BLEU (sacrebleu):\", round(bleu_sacre, 4))\n",
    "    \n",
    "    # Hiển thị ảnh với caption\n",
    "    img = load_img(img_path)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Generated: {caption}\\nReference: {reference_caption}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Chạy đánh giá\n",
    "if __name__ == \"__main__\":\n",
    "    run_evaluation_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
